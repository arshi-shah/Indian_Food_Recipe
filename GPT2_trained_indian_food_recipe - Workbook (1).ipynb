{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9Z_JV2k4aG6"
   },
   "source": [
    "## Installing Dependencies\n",
    "\n",
    "**Key Concept**: We'll use the Hugging Face `transformers` library, which provides pre-trained models and tools for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_BTO9lh8m_ym"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge-score in ./.venv/lib/python3.12/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in ./.venv/lib/python3.12/site-packages (from rouge-score) (2.4.0)\n",
      "Requirement already satisfied: nltk in ./.venv/lib/python3.12/site-packages (from rouge-score) (3.9.2)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from rouge-score) (2.4.2)\n",
      "Requirement already satisfied: six>=1.14.0 in ./.venv/lib/python3.12/site-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.12/site-packages (from nltk->rouge-score) (8.3.1)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.12/site-packages (from nltk->rouge-score) (1.5.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.12/site-packages (from nltk->rouge-score) (2026.1.15)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from nltk->rouge-score) (4.67.3)\n",
      "Requirement already satisfied: accelerate in ./.venv/lib/python3.12/site-packages (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.12/site-packages (from accelerate) (2.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from accelerate) (26.0)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.12/site-packages (from accelerate) (7.2.2)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.12/site-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in ./.venv/lib/python3.12/site-packages (from accelerate) (2.10.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in ./.venv/lib/python3.12/site-packages (from accelerate) (1.4.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from accelerate) (0.7.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.24.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (0.28.1)\n",
      "Requirement already satisfied: shellingham in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.3)\n",
      "Requirement already satisfied: typer-slim in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (0.23.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (82.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.6.0 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in ./.venv/lib/python3.12/site-packages (from cuda-bindings==12.9.4->torch>=2.0.0->accelerate) (1.3.4)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate) (4.12.1)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate) (0.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: typer>=0.23.1 in ./.venv/lib/python3.12/site-packages (from typer-slim->huggingface_hub>=0.21.0->accelerate) (0.23.1)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.12/site-packages (from typer>=0.23.1->typer-slim->huggingface_hub>=0.21.0->accelerate) (8.3.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./.venv/lib/python3.12/site-packages (from typer>=0.23.1->typer-slim->huggingface_hub>=0.21.0->accelerate) (14.3.2)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in ./.venv/lib/python3.12/site-packages (from typer>=0.23.1->typer-slim->huggingface_hub>=0.21.0->accelerate) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.12/site-packages (from rich>=10.11.0->typer>=0.23.1->typer-slim->huggingface_hub>=0.21.0->accelerate) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from rich>=10.11.0->typer>=0.23.1->typer-slim->huggingface_hub>=0.21.0->accelerate) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.23.1->typer-slim->huggingface_hub>=0.21.0->accelerate) (0.1.2)\n",
      "Requirement already satisfied: gradio in ./.venv/lib/python3.12/site-packages (6.5.1)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in ./.venv/lib/python3.12/site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in ./.venv/lib/python3.12/site-packages (from gradio) (4.12.1)\n",
      "Requirement already satisfied: brotli>=1.1.0 in ./.venv/lib/python3.12/site-packages (from gradio) (1.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in ./.venv/lib/python3.12/site-packages (from gradio) (0.129.0)\n",
      "Requirement already satisfied: ffmpy in ./.venv/lib/python3.12/site-packages (from gradio) (1.0.0)\n",
      "Requirement already satisfied: gradio-client==2.0.3 in ./.venv/lib/python3.12/site-packages (from gradio) (2.0.3)\n",
      "Requirement already satisfied: groovy~=0.1 in ./.venv/lib/python3.12/site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in ./.venv/lib/python3.12/site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in ./.venv/lib/python3.12/site-packages (from gradio) (1.4.1)\n",
      "Requirement already satisfied: jinja2<4.0 in ./.venv/lib/python3.12/site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in ./.venv/lib/python3.12/site-packages (from gradio) (3.0.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in ./.venv/lib/python3.12/site-packages (from gradio) (2.4.2)\n",
      "Requirement already satisfied: orjson~=3.0 in ./.venv/lib/python3.12/site-packages (from gradio) (3.11.7)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from gradio) (26.0)\n",
      "Requirement already satisfied: pandas<4.0,>=1.0 in ./.venv/lib/python3.12/site-packages (from gradio) (3.0.0)\n",
      "Requirement already satisfied: pillow<13.0,>=8.0 in ./.venv/lib/python3.12/site-packages (from gradio) (12.1.1)\n",
      "Requirement already satisfied: pydantic<=3.0,>=2.0 in ./.venv/lib/python3.12/site-packages (from gradio) (2.12.5)\n",
      "Requirement already satisfied: pydub in ./.venv/lib/python3.12/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in ./.venv/lib/python3.12/site-packages (from gradio) (0.0.22)\n",
      "Requirement already satisfied: pytz>=2017.2 in ./.venv/lib/python3.12/site-packages (from gradio) (2025.2)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in ./.venv/lib/python3.12/site-packages (from gradio) (6.0.3)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.7 in ./.venv/lib/python3.12/site-packages (from gradio) (0.1.7)\n",
      "Requirement already satisfied: semantic-version~=2.0 in ./.venv/lib/python3.12/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in ./.venv/lib/python3.12/site-packages (from gradio) (0.52.1)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in ./.venv/lib/python3.12/site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in ./.venv/lib/python3.12/site-packages (from gradio) (0.23.1)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in ./.venv/lib/python3.12/site-packages (from gradio) (4.15.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in ./.venv/lib/python3.12/site-packages (from gradio) (0.40.0)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from gradio-client==2.0.3->gradio) (2025.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.12/site-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.12/site-packages (from fastapi<1.0,>=0.115.2->gradio) (0.4.2)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in ./.venv/lib/python3.12/site-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx<1.0,>=0.24.1->gradio) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.24.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
      "Requirement already satisfied: shellingham in ./.venv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.3)\n",
      "Requirement already satisfied: typer-slim in ./.venv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (0.23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas<4.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<=3.0,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.12/site-packages (from pydantic<=3.0,>=2.0->gradio) (2.41.5)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.12/site-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./.venv/lib/python3.12/site-packages (from typer<1.0,>=0.12->gradio) (14.3.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<4.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages for model evaluation, training acceleration, and UI\n",
    "!pip install rouge-score      # For ROUGE evaluation metrics\n",
    "!pip install accelerate -U    # For faster training with GPU acceleration\n",
    "!pip install gradio          # For creating interactive web interfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7qkzsSQimAGt"
   },
   "source": [
    "### **Note**: After this restart the runtime to ensure all packages are properly loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mY6r_7gg4qQg"
   },
   "source": [
    "# **Data Preprocessing: Cleaning Indian Food Recipe Dataset**\n",
    "\n",
    "**Key Concept**: Data cleaning is crucial for training language models. Clean, consistent text leads to better model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1dlEUSpFYBCR"
   },
   "outputs": [],
   "source": [
    "# Import essential libraries for data manipulation and text processing\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import re           # For regular expressions and text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "COShiwsrjKJ2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'GPT2_trained_indian_food_recipe - Workbook.ipynb'   test_dataset.csv\n",
      " IndianFoodDataset.xlsx\t\t\t\t     train_dataset.csv\n",
      " cleaned_IndianFoodDataset.csv\t\t\t     validation_dataset.csv\n",
      " gpt2-indian-food\n"
     ]
    }
   ],
   "source": [
    "# Check what files are available in the current directory\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  pip install [options] [-e] <vcs project url> ...\n",
      "  pip install [options] [-e] <local project path> ...\n",
      "  pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -#\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl -q\n",
    "!pip install scikit-learn -q\n",
    "!pip install transformers -q\n",
    "!pip install torch -q\n",
    "!pip install datasets -q\n",
    "!pip install ipywidgets  -q# optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0+cu128\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ujRzWY3oZAmP"
   },
   "outputs": [],
   "source": [
    "# Load the Indian Food dataset\n",
    "# Note: Make sure your file name matches the one you uploaded\n",
    "data = pd.read_excel(\"IndianFoodDataset.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TODO 2**: Explore the Dataset\n",
    "<details>\n",
    "<summary>üí° Hint: Essential pandas methods for data exploration</summary>\n",
    "\n",
    "Use these methods to understand your data:\n",
    "- `.head()` - View first few rows\n",
    "- `.info()` - Get data types and memory usage\n",
    "- `.shape` - Get dimensions\n",
    "- `.describe()` - Get statistical summary\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cWd8Vk_IZClB"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Srno</th>\n",
       "      <th>RecipeName</th>\n",
       "      <th>TranslatedRecipeName</th>\n",
       "      <th>Ingredients</th>\n",
       "      <th>TranslatedIngredients</th>\n",
       "      <th>PrepTimeInMins</th>\n",
       "      <th>CookTimeInMins</th>\n",
       "      <th>TotalTimeInMins</th>\n",
       "      <th>Servings</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Course</th>\n",
       "      <th>Diet</th>\n",
       "      <th>Instructions</th>\n",
       "      <th>TranslatedInstructions</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Masala Karela Recipe</td>\n",
       "      <td>Masala Karela Recipe</td>\n",
       "      <td>6 Karela (Bitter Gourd/ Pavakkai) - deseeded,S...</td>\n",
       "      <td>6 Karela (Bitter Gourd/ Pavakkai) - deseeded,S...</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>f</td>\n",
       "      <td>6</td>\n",
       "      <td>Indian</td>\n",
       "      <td>Side Dish</td>\n",
       "      <td>Diabetic Friendly</td>\n",
       "      <td>To make the¬†Masala Karela Recipe,de-seed the k...</td>\n",
       "      <td>To make the¬†Masala Karela Recipe,de-seed the k...</td>\n",
       "      <td>https://www.archanaskitchen.com/masala-karela-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>‡§ü‡§Æ‡§æ‡§ü‡§∞ ‡§™‡•Å‡§≤‡§ø‡§Ø‡•ã‡§ó‡§∞‡•á ‡§∞‡•á‡§∏‡§ø‡§™‡•Ä - Spicy Tomato Rice (Re...</td>\n",
       "      <td>Spicy Tomato Rice (Recipe)</td>\n",
       "      <td>2-1/2 ‡§ï‡§™ ‡§ö‡§æ‡§µ‡§≤ - ‡§™‡§ï‡§æ ‡§≤‡•á,3 ‡§ü‡§Æ‡§æ‡§ü‡§∞,3 ‡§õ‡•ã‡§ü‡§æ ‡§ö‡§Æ‡§ö‡•ç‡§ö ‡§¨‡•Ä...</td>\n",
       "      <td>2-1 / 2 cups rice - cooked, 3 tomatoes, 3 teas...</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>South Indian Recipes</td>\n",
       "      <td>Main Course</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>‡§ü‡§Æ‡§æ‡§ü‡§∞ ‡§™‡•Å‡§≤‡§ø‡§Ø‡•ã‡§ó‡§∞‡•á ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§¨‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§ü‡§Æ‡§æ‡§ü‡§∞ ‡§ï...</td>\n",
       "      <td>To make tomato puliogere, first cut the tomato...</td>\n",
       "      <td>http://www.archanaskitchen.com/spicy-tomato-ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Ragi Semiya Upma Recipe - Ragi Millet Vermicel...</td>\n",
       "      <td>Ragi Semiya Upma Recipe - Ragi Millet Vermicel...</td>\n",
       "      <td>1-1/2 cups Rice Vermicelli Noodles (Thin),1 On...</td>\n",
       "      <td>1-1/2 cups Rice Vermicelli Noodles (Thin),1 On...</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>South Indian Recipes</td>\n",
       "      <td>South Indian Breakfast</td>\n",
       "      <td>High Protein Vegetarian</td>\n",
       "      <td>To make the Ragi Vermicelli Recipe, first stea...</td>\n",
       "      <td>To make the Ragi Vermicelli Recipe, first stea...</td>\n",
       "      <td>http://www.archanaskitchen.com/ragi-vermicelli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gongura Chicken Curry Recipe - Andhra Style Go...</td>\n",
       "      <td>Gongura Chicken Curry Recipe - Andhra Style Go...</td>\n",
       "      <td>500 grams Chicken,2 Onion - chopped,1 Tomato -...</td>\n",
       "      <td>500 grams Chicken,2 Onion - chopped,1 Tomato -...</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>Andhra</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>Non Vegeterian</td>\n",
       "      <td>To make¬†Gongura Chicken Curry Recipe first pre...</td>\n",
       "      <td>To make¬†Gongura Chicken Curry Recipe first pre...</td>\n",
       "      <td>http://www.archanaskitchen.com/gongura-chicken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>‡§Ü‡§Ç‡§ß‡•ç‡§∞‡§æ ‡§∏‡•ç‡§ü‡§æ‡§á‡§≤ ‡§Ü‡§≤‡§Æ ‡§™‡§ö‡•ú‡•Ä ‡§∞‡•á‡§∏‡§ø‡§™‡•Ä - Adrak Chutney ...</td>\n",
       "      <td>Andhra Style Alam Pachadi Recipe - Adrak Chutn...</td>\n",
       "      <td>1 ‡§¨‡•ú‡§æ ‡§ö‡§Æ‡§ö‡•ç‡§ö ‡§ö‡§®‡§æ ‡§¶‡§æ‡§≤,1 ‡§¨‡•ú‡§æ ‡§ö‡§Æ‡§ö‡•ç‡§ö ‡§∏‡•û‡•á‡§¶ ‡§â‡§∞‡§¶ ‡§¶‡§æ‡§≤,2...</td>\n",
       "      <td>1 tablespoon chana dal, 1 tablespoon white ura...</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>Andhra</td>\n",
       "      <td>South Indian Breakfast</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>‡§Ü‡§Ç‡§ß‡•ç‡§∞‡§æ ‡§∏‡•ç‡§ü‡§æ‡§á‡§≤ ‡§Ü‡§≤‡§Æ ‡§™‡§ö‡•ú‡•Ä ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§¨‡§∏‡•á ‡§™‡§π‡§≤‡•á ...</td>\n",
       "      <td>To make Andhra Style Alam Pachadi, first heat ...</td>\n",
       "      <td>https://www.archanaskitchen.com/andhra-style-a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Srno                                         RecipeName  \\\n",
       "0     1                               Masala Karela Recipe   \n",
       "1     2  ‡§ü‡§Æ‡§æ‡§ü‡§∞ ‡§™‡•Å‡§≤‡§ø‡§Ø‡•ã‡§ó‡§∞‡•á ‡§∞‡•á‡§∏‡§ø‡§™‡•Ä - Spicy Tomato Rice (Re...   \n",
       "2     3  Ragi Semiya Upma Recipe - Ragi Millet Vermicel...   \n",
       "3     4  Gongura Chicken Curry Recipe - Andhra Style Go...   \n",
       "4     5  ‡§Ü‡§Ç‡§ß‡•ç‡§∞‡§æ ‡§∏‡•ç‡§ü‡§æ‡§á‡§≤ ‡§Ü‡§≤‡§Æ ‡§™‡§ö‡•ú‡•Ä ‡§∞‡•á‡§∏‡§ø‡§™‡•Ä - Adrak Chutney ...   \n",
       "\n",
       "                                TranslatedRecipeName  \\\n",
       "0                               Masala Karela Recipe   \n",
       "1                         Spicy Tomato Rice (Recipe)   \n",
       "2  Ragi Semiya Upma Recipe - Ragi Millet Vermicel...   \n",
       "3  Gongura Chicken Curry Recipe - Andhra Style Go...   \n",
       "4  Andhra Style Alam Pachadi Recipe - Adrak Chutn...   \n",
       "\n",
       "                                         Ingredients  \\\n",
       "0  6 Karela (Bitter Gourd/ Pavakkai) - deseeded,S...   \n",
       "1  2-1/2 ‡§ï‡§™ ‡§ö‡§æ‡§µ‡§≤ - ‡§™‡§ï‡§æ ‡§≤‡•á,3 ‡§ü‡§Æ‡§æ‡§ü‡§∞,3 ‡§õ‡•ã‡§ü‡§æ ‡§ö‡§Æ‡§ö‡•ç‡§ö ‡§¨‡•Ä...   \n",
       "2  1-1/2 cups Rice Vermicelli Noodles (Thin),1 On...   \n",
       "3  500 grams Chicken,2 Onion - chopped,1 Tomato -...   \n",
       "4  1 ‡§¨‡•ú‡§æ ‡§ö‡§Æ‡§ö‡•ç‡§ö ‡§ö‡§®‡§æ ‡§¶‡§æ‡§≤,1 ‡§¨‡•ú‡§æ ‡§ö‡§Æ‡§ö‡•ç‡§ö ‡§∏‡•û‡•á‡§¶ ‡§â‡§∞‡§¶ ‡§¶‡§æ‡§≤,2...   \n",
       "\n",
       "                               TranslatedIngredients  PrepTimeInMins  \\\n",
       "0  6 Karela (Bitter Gourd/ Pavakkai) - deseeded,S...              15   \n",
       "1  2-1 / 2 cups rice - cooked, 3 tomatoes, 3 teas...               5   \n",
       "2  1-1/2 cups Rice Vermicelli Noodles (Thin),1 On...              20   \n",
       "3  500 grams Chicken,2 Onion - chopped,1 Tomato -...              15   \n",
       "4  1 tablespoon chana dal, 1 tablespoon white ura...              10   \n",
       "\n",
       "   CookTimeInMins TotalTimeInMins  Servings               Cuisine  \\\n",
       "0              30               f         6                Indian   \n",
       "1              10              15         3  South Indian Recipes   \n",
       "2              30              50         4  South Indian Recipes   \n",
       "3              30              45         4                Andhra   \n",
       "4              20              30         4                Andhra   \n",
       "\n",
       "                   Course                     Diet  \\\n",
       "0               Side Dish        Diabetic Friendly   \n",
       "1             Main Course               Vegetarian   \n",
       "2  South Indian Breakfast  High Protein Vegetarian   \n",
       "3                   Lunch           Non Vegeterian   \n",
       "4  South Indian Breakfast               Vegetarian   \n",
       "\n",
       "                                        Instructions  \\\n",
       "0  To make the¬†Masala Karela Recipe,de-seed the k...   \n",
       "1  ‡§ü‡§Æ‡§æ‡§ü‡§∞ ‡§™‡•Å‡§≤‡§ø‡§Ø‡•ã‡§ó‡§∞‡•á ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§¨‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§ü‡§Æ‡§æ‡§ü‡§∞ ‡§ï...   \n",
       "2  To make the Ragi Vermicelli Recipe, first stea...   \n",
       "3  To make¬†Gongura Chicken Curry Recipe first pre...   \n",
       "4  ‡§Ü‡§Ç‡§ß‡•ç‡§∞‡§æ ‡§∏‡•ç‡§ü‡§æ‡§á‡§≤ ‡§Ü‡§≤‡§Æ ‡§™‡§ö‡•ú‡•Ä ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§¨‡§∏‡•á ‡§™‡§π‡§≤‡•á ...   \n",
       "\n",
       "                              TranslatedInstructions  \\\n",
       "0  To make the¬†Masala Karela Recipe,de-seed the k...   \n",
       "1  To make tomato puliogere, first cut the tomato...   \n",
       "2  To make the Ragi Vermicelli Recipe, first stea...   \n",
       "3  To make¬†Gongura Chicken Curry Recipe first pre...   \n",
       "4  To make Andhra Style Alam Pachadi, first heat ...   \n",
       "\n",
       "                                                 URL  \n",
       "0  https://www.archanaskitchen.com/masala-karela-...  \n",
       "1  http://www.archanaskitchen.com/spicy-tomato-ri...  \n",
       "2  http://www.archanaskitchen.com/ragi-vermicelli...  \n",
       "3  http://www.archanaskitchen.com/gongura-chicken...  \n",
       "4  https://www.archanaskitchen.com/andhra-style-a...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Display the first 5 rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UiE5wiOBaojl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 1186 entries, 0 to 1185\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   Srno                    1186 non-null   int64 \n",
      " 1   RecipeName              1186 non-null   str   \n",
      " 2   TranslatedRecipeName    1186 non-null   str   \n",
      " 3   Ingredients             1185 non-null   str   \n",
      " 4   TranslatedIngredients   1185 non-null   str   \n",
      " 5   PrepTimeInMins          1186 non-null   int64 \n",
      " 6   CookTimeInMins          1186 non-null   int64 \n",
      " 7   TotalTimeInMins         1186 non-null   object\n",
      " 8   Servings                1186 non-null   int64 \n",
      " 9   Cuisine                 1186 non-null   str   \n",
      " 10  Course                  1186 non-null   str   \n",
      " 11  Diet                    1186 non-null   str   \n",
      " 12  Instructions            1186 non-null   str   \n",
      " 13  TranslatedInstructions  1186 non-null   str   \n",
      " 14  URL                     1186 non-null   str   \n",
      "dtypes: int64(4), object(1), str(10)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# TODO: Get information about the dataset structure\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Understanding Data Selection for Language Models**\n",
    "\n",
    "**Key Concept**: For training a language model, we need to decide which columns contain the text we want the model to learn from. In this case, we're focusing on recipe instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "P-OtRokAbHIt"
   },
   "outputs": [],
   "source": [
    "# Remove columns we don't need for language model training\n",
    "# We keep only the translated text columns for training\n",
    "data = data.drop(['Srno', 'RecipeName', 'Ingredients', 'Instructions'], axis=1)\n",
    "\n",
    "# Why drop these? We focus on translated versions for consistency\n",
    "# and 'Srno' is just an index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XT9I2OtObxjy"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TranslatedRecipeName</th>\n",
       "      <th>TranslatedIngredients</th>\n",
       "      <th>PrepTimeInMins</th>\n",
       "      <th>CookTimeInMins</th>\n",
       "      <th>TotalTimeInMins</th>\n",
       "      <th>Servings</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Course</th>\n",
       "      <th>Diet</th>\n",
       "      <th>TranslatedInstructions</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Masala Karela Recipe</td>\n",
       "      <td>6 Karela (Bitter Gourd/ Pavakkai) - deseeded,S...</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>f</td>\n",
       "      <td>6</td>\n",
       "      <td>Indian</td>\n",
       "      <td>Side Dish</td>\n",
       "      <td>Diabetic Friendly</td>\n",
       "      <td>To make the¬†Masala Karela Recipe,de-seed the k...</td>\n",
       "      <td>https://www.archanaskitchen.com/masala-karela-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spicy Tomato Rice (Recipe)</td>\n",
       "      <td>2-1 / 2 cups rice - cooked, 3 tomatoes, 3 teas...</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>South Indian Recipes</td>\n",
       "      <td>Main Course</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>To make tomato puliogere, first cut the tomato...</td>\n",
       "      <td>http://www.archanaskitchen.com/spicy-tomato-ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ragi Semiya Upma Recipe - Ragi Millet Vermicel...</td>\n",
       "      <td>1-1/2 cups Rice Vermicelli Noodles (Thin),1 On...</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>South Indian Recipes</td>\n",
       "      <td>South Indian Breakfast</td>\n",
       "      <td>High Protein Vegetarian</td>\n",
       "      <td>To make the Ragi Vermicelli Recipe, first stea...</td>\n",
       "      <td>http://www.archanaskitchen.com/ragi-vermicelli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gongura Chicken Curry Recipe - Andhra Style Go...</td>\n",
       "      <td>500 grams Chicken,2 Onion - chopped,1 Tomato -...</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>Andhra</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>Non Vegeterian</td>\n",
       "      <td>To make¬†Gongura Chicken Curry Recipe first pre...</td>\n",
       "      <td>http://www.archanaskitchen.com/gongura-chicken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andhra Style Alam Pachadi Recipe - Adrak Chutn...</td>\n",
       "      <td>1 tablespoon chana dal, 1 tablespoon white ura...</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>Andhra</td>\n",
       "      <td>South Indian Breakfast</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>To make Andhra Style Alam Pachadi, first heat ...</td>\n",
       "      <td>https://www.archanaskitchen.com/andhra-style-a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                TranslatedRecipeName  \\\n",
       "0                               Masala Karela Recipe   \n",
       "1                         Spicy Tomato Rice (Recipe)   \n",
       "2  Ragi Semiya Upma Recipe - Ragi Millet Vermicel...   \n",
       "3  Gongura Chicken Curry Recipe - Andhra Style Go...   \n",
       "4  Andhra Style Alam Pachadi Recipe - Adrak Chutn...   \n",
       "\n",
       "                               TranslatedIngredients  PrepTimeInMins  \\\n",
       "0  6 Karela (Bitter Gourd/ Pavakkai) - deseeded,S...              15   \n",
       "1  2-1 / 2 cups rice - cooked, 3 tomatoes, 3 teas...               5   \n",
       "2  1-1/2 cups Rice Vermicelli Noodles (Thin),1 On...              20   \n",
       "3  500 grams Chicken,2 Onion - chopped,1 Tomato -...              15   \n",
       "4  1 tablespoon chana dal, 1 tablespoon white ura...              10   \n",
       "\n",
       "   CookTimeInMins TotalTimeInMins  Servings               Cuisine  \\\n",
       "0              30               f         6                Indian   \n",
       "1              10              15         3  South Indian Recipes   \n",
       "2              30              50         4  South Indian Recipes   \n",
       "3              30              45         4                Andhra   \n",
       "4              20              30         4                Andhra   \n",
       "\n",
       "                   Course                     Diet  \\\n",
       "0               Side Dish        Diabetic Friendly   \n",
       "1             Main Course               Vegetarian   \n",
       "2  South Indian Breakfast  High Protein Vegetarian   \n",
       "3                   Lunch           Non Vegeterian   \n",
       "4  South Indian Breakfast               Vegetarian   \n",
       "\n",
       "                              TranslatedInstructions  \\\n",
       "0  To make the¬†Masala Karela Recipe,de-seed the k...   \n",
       "1  To make tomato puliogere, first cut the tomato...   \n",
       "2  To make the Ragi Vermicelli Recipe, first stea...   \n",
       "3  To make¬†Gongura Chicken Curry Recipe first pre...   \n",
       "4  To make Andhra Style Alam Pachadi, first heat ...   \n",
       "\n",
       "                                                 URL  \n",
       "0  https://www.archanaskitchen.com/masala-karela-...  \n",
       "1  http://www.archanaskitchen.com/spicy-tomato-ri...  \n",
       "2  http://www.archanaskitchen.com/ragi-vermicelli...  \n",
       "3  http://www.archanaskitchen.com/gongura-chicken...  \n",
       "4  https://www.archanaskitchen.com/andhra-style-a...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Missing Data\n",
    "<details>\n",
    "<summary>Methods for handling missing values</summary>\n",
    "\n",
    "Common approaches:\n",
    "- `.isnull().sum()` - Count missing values\n",
    "- `.dropna()` - Remove rows with missing values\n",
    "- `.fillna()` - Fill missing values with specific values\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "C5MKDdfNaZbt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TranslatedRecipeName      0\n",
       "TranslatedIngredients     1\n",
       "PrepTimeInMins            0\n",
       "CookTimeInMins            0\n",
       "TotalTimeInMins           0\n",
       "Servings                  0\n",
       "Cuisine                   0\n",
       "Course                    0\n",
       "Diet                      0\n",
       "TranslatedInstructions    0\n",
       "URL                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Check for missing values in each column\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "o8FSiqKfjqLk"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TranslatedRecipeName</th>\n",
       "      <th>TranslatedIngredients</th>\n",
       "      <th>PrepTimeInMins</th>\n",
       "      <th>CookTimeInMins</th>\n",
       "      <th>TotalTimeInMins</th>\n",
       "      <th>Servings</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Course</th>\n",
       "      <th>Diet</th>\n",
       "      <th>TranslatedInstructions</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Pear And Walnut Salad Recipe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>Continental</td>\n",
       "      <td>Appetizer</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>To make the Pear And Walnut Salad Recipe, firs...</td>\n",
       "      <td>https://www.archanaskitchen.com/pear-and-walnu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TranslatedRecipeName TranslatedIngredients  PrepTimeInMins  \\\n",
       "287  Pear And Walnut Salad Recipe                   NaN              10   \n",
       "\n",
       "     CookTimeInMins TotalTimeInMins  Servings      Cuisine     Course  \\\n",
       "287              30              40         2  Continental  Appetizer   \n",
       "\n",
       "           Diet                             TranslatedInstructions  \\\n",
       "287  Vegetarian  To make the Pear And Walnut Salad Recipe, firs...   \n",
       "\n",
       "                                                   URL  \n",
       "287  https://www.archanaskitchen.com/pear-and-walnu...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify specific rows that have missing values\n",
    "# This helps us understand the extent of missing data\n",
    "\n",
    "data[data[\"TranslatedIngredients\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "G6PTG0niafhH"
   },
   "outputs": [],
   "source": [
    "# TODO: Remove rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Alternative approach: You could also fill missing values\n",
    "# data = data.fillna(\"Unknown recipe step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Text Cleaning for NLP**\n",
    "\n",
    "**Key Concept**: Text cleaning standardizes the input format, removing noise that could confuse the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "RRePNwqDbFRS"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean text by removing special characters and normalizing whitespace.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to clean\n",
    "        \n",
    "    Returns:\n",
    "        str: Cleaned text\n",
    "    \"\"\"\n",
    "    # Remove non-alphanumeric characters (keep letters, numbers, and spaces, and some basic punctuation marks )\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s.,!?'-]\", \"\", text)\n",
    "    \n",
    "    # Replace multiple whitespaces with single space and strip leading/trailing spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply text cleaning to all text columns\n",
    "text_columns = ['TranslatedRecipeName', 'TranslatedIngredients', 'TranslatedInstructions']\n",
    "for column in text_columns:\n",
    "    data[column] = data[column].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Gi7FMHkxcFe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved with 1185 recipes\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned dataset for later use\n",
    "data.to_csv(\"cleaned_IndianFoodDataset.csv\", index=False)\n",
    "print(f\"Cleaned dataset saved with {len(data)} recipes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_1aZEGSaANm"
   },
   "source": [
    "# **Fine-tuning GPT-2 Model**\n",
    "\n",
    "**Key Concept**: Fine-tuning involves taking a pre-trained model and training it further on domain-specific data (Indian food recipes) to make it specialized for that domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "4N-RwTIOce_N"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arshi/Programming/chatbot_dev/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import libraries for model training and data handling\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    GPT2LMHeadModel,              # Pre-trained GPT-2 model for text generation\n",
    "    GPT2Tokenizer,               # Tokenizer to convert text to tokens                 \n",
    "    DataCollatorForLanguageModeling,  # Handles batching for language modeling\n",
    "    Trainer,                     # High-level training interface\n",
    "    TrainingArguments           # Configuration for training parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "zDV4WexNcfpS"
   },
   "outputs": [],
   "source": [
    "# Load the cleaned dataset\n",
    "data = pd.read_csv(\"cleaned_IndianFoodDataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Training Data\n",
    "<details>\n",
    "<summary>Choosing the right column for language modeling</summary>\n",
    "\n",
    "For recipe generation, we want the model to learn cooking instructions. Consider:\n",
    "- `TranslatedInstructions` - Step-by-step cooking process\n",
    "- `TranslatedIngredients` - List of ingredients\n",
    "- `TranslatedRecipeName` - Recipe names\n",
    "\n",
    "Instructions are most suitable for generating coherent cooking steps.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Kh3cCdpd5U_5"
   },
   "outputs": [],
   "source": [
    "# TODO: Select the column to train the language model on\n",
    "text_data = data['TranslatedInstructions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "qBZZ2JOU5efj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       To make the Masala Karela Recipe,de-seed the k...\n",
       "1       To make tomato puliogere, first cut the tomato...\n",
       "2       To make the Ragi Vermicelli Recipe, first stea...\n",
       "3       To make Gongura Chicken Curry Recipe first pre...\n",
       "4       To make Andhra Style Alam Pachadi, first heat ...\n",
       "                              ...                        \n",
       "1180    To make the Cheesy Pasta Casserole With Brocco...\n",
       "1181    To make the Insalata Caprese Salad Recipe, we ...\n",
       "1182    To make the Mutton Matar Keema Recipe, firstly...\n",
       "1183    To make the Rajma Wrap, soak the rajma overnig...\n",
       "1184    To make the spinach chana dal recipe, first so...\n",
       "Name: TranslatedInstructions, Length: 1185, dtype: str"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the selected text data\n",
    "text_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Splitting Strategy**\n",
    "\n",
    "**Key Concept**: We split data into train/validation/test sets to:\n",
    "- **Train**: Learn patterns from the data\n",
    "- **Validation**: Monitor training progress and prevent overfitting\n",
    "- **Test**: Final evaluation on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "isNfAKFFchLG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 948\n",
      "Validation samples: 119\n",
      "Test samples: 118\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into train, validation, and test sets\n",
    "# Using 80-10-10 split for train-val-test\n",
    "SEED = 7  # For reproducible results\n",
    "\n",
    "# First split: 80% train, 20% temporary\n",
    "train_data, temp_data = train_test_split(text_data, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# Second split: Split the 20% into 10% test and 10% validation\n",
    "test_data, validation_data = train_test_split(temp_data, test_size=0.5, random_state=SEED)\n",
    "\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Validation samples: {len(validation_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "EtrUTnyCcjUr"
   },
   "outputs": [],
   "source": [
    "# Save the split datasets as CSV files\n",
    "# This allows us to reload them later without re-splitting\n",
    "train_data.to_csv(\"train_dataset.csv\", index=False)\n",
    "validation_data.to_csv(\"validation_dataset.csv\", index=False)\n",
    "test_data.to_csv(\"test_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.10.0\n",
      "Uninstalling torch-2.10.0:\n",
      "  Successfully uninstalled torch-2.10.0\n",
      "\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting torch\n",
      "  Using cached torch-2.10.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch) (3.24.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch) (82.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.12/site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.12/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in ./.venv/lib/python3.12/site-packages (from torch) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib/python3.12/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in ./.venv/lib/python3.12/site-packages (from torch) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.6.0 in ./.venv/lib/python3.12/site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in ./.venv/lib/python3.12/site-packages (from cuda-bindings==12.9.4->torch) (1.3.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "Using cached torch-2.10.0-cp312-cp312-manylinux_2_28_x86_64.whl (915.7 MB)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch torchvision torchaudio -y\n",
    "!pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0+cu128\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model and Tokenizer Setup**\n",
    "\n",
    "**Key Concept**: \n",
    "- **Tokenizer**: Converts text into numbers (tokens) that the model can understand\n",
    "- **Model**: The neural network that learns to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "GldYHqxjn-Gx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 148/148 [00:00<00:00, 305.27it/s, Materializing param=transformer.wte.weight]\n",
      "\u001b[1mGPT2LMHeadModel LOAD REPORT\u001b[0m from: gpt2\n",
      "Key                  | Status     |  | \n",
      "---------------------+------------+--+-\n",
      "h.{0...11}.attn.bias | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained GPT-2 tokenizer and model\n",
    "# These are trained on general English text and will be fine-tuned on our recipe data\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "\n",
    "# Add padding token (GPT-2 doesn't have one by default)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Block Size\n",
    "<details>\n",
    "<summary>What is block_size in language modeling?</summary>\n",
    "\n",
    "`block_size` is the maximum sequence length:\n",
    "- **128**: Good for shorter texts, faster training\n",
    "- **512**: Better for longer contexts, slower training\n",
    "- **1024**: Maximum context, very slow training\n",
    "\n",
    "For recipe instructions, 128 tokens is usually sufficient.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ZQ2RYt2icnH3"
   },
   "outputs": [],
   "source": [
    "# # Create TextDataset objects for training\n",
    "# # These handle the conversion of text to tokenized sequences\n",
    "\n",
    "# train_dataset = TextDataset(\n",
    "#     tokenizer=tokenizer,           # The tokenizer to convert text into tokens\n",
    "#     file_path=\"train_dataset.csv\", # Path to the CSV file containing training data\n",
    "#     block_size=128                 # Maximum length of each input sequence (in tokens)\n",
    "#                                   # TODO: Try experimenting with different values: 64, 256, 512\n",
    "# )\n",
    "\n",
    "# validation_dataset = TextDataset(\n",
    "#     tokenizer=tokenizer,\n",
    "#     file_path=\"validation_dataset.csv\",\n",
    "#     block_size=128\n",
    "# )\n",
    "\n",
    "# test_dataset = TextDataset(\n",
    "#     tokenizer=tokenizer,\n",
    "#     file_path=\"test_dataset.csv\",\n",
    "#     block_size=128\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 948 examples [00:00, 31374.87 examples/s]\n",
      "Generating validation split: 119 examples [00:00, 12983.43 examples/s]\n",
      "Generating test split: 118 examples [00:00, 19314.26 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['TranslatedInstructions']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files={\n",
    "        \"train\": \"train_dataset.csv\",\n",
    "        \"validation\": \"validation_dataset.csv\",\n",
    "        \"test\": \"test_dataset.csv\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Check available columns\n",
    "print(\"Columns:\", dataset[\"train\"].column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 948/948 [00:00<00:00, 3906.64 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 119/119 [00:00<00:00, 2260.97 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 118/118 [00:00<00:00, 3052.00 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"TranslatedInstructions\"],  # change if needed\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "_XP2BqNMleWU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 948\n",
      "Validation size: 119\n",
      "Test size: 118\n"
     ]
    }
   ],
   "source": [
    "print(\"Train size:\", len(tokenized_dataset[\"train\"]))\n",
    "print(\"Validation size:\", len(tokenized_dataset[\"validation\"]))\n",
    "print(\"Test size:\", len(tokenized_dataset[\"test\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training Configuration**\n",
    "\n",
    "**Key Concept**: Training arguments control how the model learns. Key parameters include:\n",
    "- **Epochs**: How many times to go through the entire dataset\n",
    "- **Batch size**: How many examples to process together\n",
    "- **Learning rate**: How fast the model updates its weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "5VeDiyUScrf9"
   },
   "outputs": [],
   "source": [
    "# TODO: Configure training arguments\n",
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-indian-food\",     # Directory to save model checkpoints\n",
    "    num_train_epochs=3,                  # TODO: Try 1, 2, 3, or 5 epochs\n",
    "    per_device_train_batch_size= 16,    # TODO: Fill in batch size (try 8, 16, 32) [Don't go beyond 32 as we need higher GPU!]\n",
    "    save_steps=10_000,                   # Save checkpoint every 10,000 steps\n",
    "    save_total_limit=2,                  # Keep only 2 most recent checkpoints\n",
    "    prediction_loss_only=True,           # Only compute loss during evaluation\n",
    "    logging_steps=100,                   # Log training progress every 100 steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "qXMMtkjBcvKK"
   },
   "outputs": [],
   "source": [
    "# Set up the trainer - this handles the training loop\n",
    "from transformers import Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                    # The GPT-2 model to fine-tune\n",
    "    args=training_args,             # Training configuration from above\n",
    "    \n",
    "    # Data collator prepares batches of data for training\n",
    "    data_collator=DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer,        # Tokenizer for processing text\n",
    "        mlm=False                  # No masked language modeling (GPT-2 uses causal LM)\n",
    "    ),\n",
    "    \n",
    "    train_dataset=tokenized_dataset[\"train\"],      # Training data\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],    # Validation data for monitoring progress\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Training**\n",
    "\n",
    "**‚ö†Ô∏è Note**: This step will take time depending on your hardware. On a GPU, expect 10-30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "e2DSDc6odGLG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arshi/Programming/chatbot_dev/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  super().__init__(loader)\n",
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='180' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [180/180 35:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.774771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing model shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Start the fine-tuning process\n",
    "# This will train the model on your recipe data\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "fIr-cOAQdIAj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing model shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the fine-tuned model and tokenizer\n",
    "trainer.save_model(\"gpt2-indian-food\")\n",
    "tokenizer.save_pretrained(\"gpt2-indian-food\")\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "4HHr8yqbdf53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arshi/Programming/chatbot_dev/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "{'eval_loss': 2.5109846591949463, 'eval_runtime': 25.4128, 'eval_samples_per_second': 4.643, 'eval_steps_per_second': 0.59, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "print(\"Evaluating model on test data...\")\n",
    "results = trainer.evaluate(tokenized_dataset[\"test\"])\n",
    "print(\"Test Results:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "FO2H-ghDthRL"
   },
   "outputs": [],
   "source": [
    "# Optional: Download model files from Google Colab to local machine\n",
    "# Uncomment these lines if you want to download the trained model\n",
    "\n",
    "# from google.colab import files\n",
    "# !zip -r gpt2-indian-food.zip gpt2-indian-food\n",
    "# files.download('gpt2-indian-food.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ueAX7Gpt5dYP"
   },
   "source": [
    "# **Model Evaluation: BLEU & ROUGE Metrics**\n",
    "\n",
    "**Key Concept**: \n",
    "- **BLEU**: Measures overlap of n-grams between generated and reference text\n",
    "- **ROUGE**: Measures recall-oriented overlap, useful for summarization and generation tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Yg0dg6IYjP1y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/arshi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/arshi/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/arshi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import evaluation libraries\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Text Generation Function**\n",
    "\n",
    "**Key Concept**: Text generation parameters:\n",
    "- **max_length**: Maximum tokens to generate\n",
    "- **temperature**: Controls randomness (lower = more deterministic)\n",
    "- **num_beams**: Beam search for better quality\n",
    "- **no_repeat_ngram_size**: Prevents repetitive phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why Use Beam Search?\n",
    "\n",
    "* Advantages:\n",
    "    - Better Quality: Explores multiple paths, often finding better overall sequences\n",
    "    - Reduced Repetition: Less likely to get stuck in repetitive loops\n",
    "    - More Coherent: Considers context across multiple words, not just the immediate next word\n",
    "\n",
    "* Trade-offs:\n",
    "    - Computational Cost: 5x more expensive than greedy decoding\n",
    "    - Slower Generation: Takes longer to produce text\n",
    "    - Memory Usage: Stores multiple candidate sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "dbgXCiQH8T90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 148/148 [00:00<00:00, 246.16it/s, Materializing param=transformer.wte.weight]\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample generation:\n",
      "To make dal, first heat oil in a heavy bottomed pan. Add onions and saute for a couple of minutes until they turn translucent.Add ginger, garlic paste, coriander leaves, red chilli powder, cumin seeds, turmeric powder and let it crackle.Once done, add tomatoes and cook till the tomatoes turn golden brown in colour. Turn off the heat and allow it to cool down.In a mixer grinder, combine all the ingredients mentioned in the recipe\n"
     ]
    }
   ],
   "source": [
    "# Load the fine-tuned model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-indian-food\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "def generate_text(prompt, max_length=100, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Generate text using the fine-tuned model.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): Starting text for generation\n",
    "        max_length (int): Maximum length of generated text\n",
    "        temperature (float): Controls randomness (0.1 = very focused, 2.0 = very random)\n",
    "    \n",
    "    Returns:\n",
    "        str: Generated text including the prompt\n",
    "    \"\"\"\n",
    "    # Convert text to tokens\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate text using beam search for better quality\n",
    "    output = model.generate(\n",
    "        input_ids, \n",
    "        max_length=max_length, \n",
    "        temperature=temperature,\n",
    "        num_beams=5,                    # Beam search for quality\n",
    "        no_repeat_ngram_size=2,         # Prevent repetition\n",
    "        do_sample=True,                 # Enable sampling\n",
    "        top_k=50,                       # Top-k sampling\n",
    "        top_p=0.95,                     # Nucleus sampling\n",
    "    )\n",
    "    \n",
    "    # Convert tokens back to text\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "# Test the generation function\n",
    "sample_output = generate_text(\"To make dal,\")\n",
    "print(\"Sample generation:\")\n",
    "print(sample_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "q71oXLMY8xL6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short generation:\n",
      "To make dal, firstly heat oil in a heavy bottomed pan. Add the mustard seeds\n"
     ]
    }
   ],
   "source": [
    "# Try with shorter generation\n",
    "short_output = generate_text(\"To make dal,\", max_length=20)\n",
    "print(\"Short generation:\")\n",
    "print(short_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TODO 6**: Create Your Own Test Cases\n",
    "<details>\n",
    "<summary>üí° Hint: Creating good test prompts and references</summary>\n",
    "\n",
    "Good test cases should:\n",
    "- Start with common recipe beginnings (\"To make...\", \"First...\", \"Heat oil...\")\n",
    "- Have realistic reference completions\n",
    "- Cover different types of cooking steps (prep, cooking, seasoning)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "HwmE3KMIisr-"
   },
   "outputs": [],
   "source": [
    "# Example prompts and references for evaluation\n",
    "prompts = [\n",
    "    \"To make Masala Karela,\",\n",
    "    \"to make Tomato Puliogere is prepared by\",\n",
    "    \"To make Ragi Vermicelli Recipe starts with\",\n",
    "    \"To make Gongura Chicken Curry Recipe first prep all the ingredients\",\n",
    "    \"To make Andhra Style Alam Pachadi is made by\"\n",
    "]\n",
    "\n",
    "references = [\n",
    "    \"To make the Masala Karela Recipe, de-seed the karela and slice.\",\n",
    "    \"To make tomato puliogere, first cut the tomatoes.\",\n",
    "    \"To begin making the Ragi Vermicelli Recipe, first steam the ragi vermicelli.\",\n",
    "    \"To begin making Gongura Chicken Curry Recipe, first prep all the ingredients.\",\n",
    "    \"To make Andhra Style Alam Pachadi, first heat oil in a pan.\"\n",
    "]\n",
    "\n",
    "# TODO: Add your own test cases\n",
    "# prompts.append(\"____\")\n",
    "# references.append(\"____\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "-QdF5xdK8M0d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Evaluation Results ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 1:\n",
      "Prompt: To make Masala Karela,\n",
      "Generated: To make Masala Karela, first heat oil in a heavy bottomed pan. Add mustard seeds and saute for a few seconds.Add turmeric powder, coriander powder and red chilli powder. Saute until it becomes soft.\n",
      "Reference: To make the Masala Karela Recipe, de-seed the karela and slice.\n",
      "BLEU Score: 0.0138\n",
      "ROUGE-1 F1: 0.2553\n",
      "ROUGE-L F1: 0.2553\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 2:\n",
      "Prompt: to make Tomato Puliogere is prepared by\n",
      "Generated: to make Tomato Puliogere is prepared by soaking tomatoes in water for 2 to 3 hours.In a large mixing bowl, combine all the ingredients mentioned in the recipe and mix well. Add salt and pepper to taste. Mix well and keep aside\n",
      "Reference: To make tomato puliogere, first cut the tomatoes.\n",
      "BLEU Score: 0.0052\n",
      "ROUGE-1 F1: 0.2353\n",
      "ROUGE-L F1: 0.1961\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 3:\n",
      "Prompt: To make Ragi Vermicelli Recipe starts with\n",
      "Generated: To make Ragi Vermicelli Recipe starts with making the dough.In a mixing bowl, combine all the ingredients mentioned in the previous step and knead for about 3-4 minutes. Keep aside.Heat oil in a heavy bottomed pan\n",
      "Reference: To begin making the Ragi Vermicelli Recipe, first steam the ragi vermicelli.\n",
      "BLEU Score: 0.0171\n",
      "ROUGE-1 F1: 0.2745\n",
      "ROUGE-L F1: 0.2353\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 4:\n",
      "Prompt: To make Gongura Chicken Curry Recipe first prep all the ingredients\n",
      "Generated: To make Gongura Chicken Curry Recipe first prep all the ingredients and keep them ready.Heat oil in a heavy bottomed pan on medium flame. Add garlic, ginger, green chillies, coriander leaves and saute for a few seconds.\n",
      "Reference: To begin making Gongura Chicken Curry Recipe, first prep all the ingredients.\n",
      "BLEU Score: 0.0933\n",
      "ROUGE-1 F1: 0.4400\n",
      "ROUGE-L F1: 0.4400\n",
      "--------------------------------------------------------------------------------\n",
      "Test Case 5:\n",
      "Prompt: To make Andhra Style Alam Pachadi is made by\n",
      "Generated: To make Andhra Style Alam Pachadi is made by mixing all the ingredients in a mixer grinder and grind it into a smooth paste.Add chopped onions, green chillies, red chilli powder, cumin seeds, coriander powder\n",
      "Reference: To make Andhra Style Alam Pachadi, first heat oil in a pan.\n",
      "BLEU Score: 0.1137\n",
      "ROUGE-1 F1: 0.3333\n",
      "ROUGE-L F1: 0.3333\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìä Average BLEU Score: 0.0486\n",
      "\n",
      "üí° Score Interpretation:\n",
      "   BLEU 0.0-0.3: Poor quality\n",
      "   BLEU 0.3-0.5: Reasonable quality\n",
      "   BLEU 0.5+: Good quality\n"
     ]
    }
   ],
   "source": [
    "# Generate text and calculate BLEU and ROUGE scores\n",
    "smooth = SmoothingFunction().method1  # Smoothing function for BLEU score\n",
    "bleu_scores = []\n",
    "rouge_scores = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "print(\"=== Model Evaluation Results ===\")\n",
    "print()\n",
    "\n",
    "for i, (prompt, reference) in enumerate(zip(prompts, references), 1):\n",
    "    # Generate text using our fine-tuned model\n",
    "    generated_text = generate_text(prompt, max_length=50)\n",
    "    \n",
    "    # Calculate BLEU score (measures n-gram overlap)\n",
    "    bleu_score = sentence_bleu([reference.split()], generated_text.split(), smoothing_function=smooth)\n",
    "    bleu_scores.append(bleu_score)\n",
    "    \n",
    "    # Calculate ROUGE scores (measures recall-oriented overlap)\n",
    "    rouge_score = rouge_scores.score(generated_text, reference)\n",
    "    \n",
    "    print(f\"Test Case {i}:\")\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Generated: {generated_text}\")\n",
    "    print(f\"Reference: {reference}\")\n",
    "    print(f\"BLEU Score: {bleu_score:.4f}\")\n",
    "    print(f\"ROUGE-1 F1: {rouge_score['rouge1'].fmeasure:.4f}\")\n",
    "    print(f\"ROUGE-L F1: {rouge_score['rougeL'].fmeasure:.4f}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Calculate and display average scores\n",
    "average_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "print(f\"\\nüìä Average BLEU Score: {average_bleu:.4f}\")\n",
    "print(\"\\nüí° Score Interpretation:\")\n",
    "print(\"   BLEU 0.0-0.3: Poor quality\")\n",
    "print(\"   BLEU 0.3-0.5: Reasonable quality\")\n",
    "print(\"   BLEU 0.5+: Good quality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mCarz9B5myQ"
   },
   "source": [
    "# **Interactive Model Testing with Gradio**\n",
    "\n",
    "**Key Concept**: Gradio allows us to create user-friendly interfaces for testing our model interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "u3xb_E0xvtGD"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "HsFl0ebPv2FE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 148/148 [00:00<00:00, 243.58it/s, Materializing param=transformer.wte.weight]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the fine-tuned model and tokenizer for interactive testing\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model_finetuned = GPT2LMHeadModel.from_pretrained(\"gpt2-indian-food\")\n",
    "\n",
    "print(\"Fine-tuned model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "j_ZU6P9o0oxu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type: <class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'>\n",
      "Number of parameters: 124,439,808\n"
     ]
    }
   ],
   "source": [
    "# Display model information\n",
    "print(f\"Model type: {type(model_finetuned)}\")\n",
    "print(f\"Number of parameters: {model_finetuned.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TK6_w9mz9MCU"
   },
   "source": [
    "### **Understanding Temperature in Text Generation**\n",
    "\n",
    "**Key Concept**: Temperature controls the randomness of text generation:\n",
    "- **Low (0.1-0.7)**: More focused, deterministic output\n",
    "- **Medium (0.8-1.2)**: Balanced creativity and coherence\n",
    "- **High (1.3-2.0)**: More creative but potentially less coherent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "6VY0DA2K9XvF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üå°Ô∏è Temperature Comparison:\n",
      "\n",
      "Temperature 0.5: To prepare chicken curry, firstly heat oil in a heavy bottomed pan. Add mustard seeds, turmeric powder, coriander powder and saute for a minute or two.Add chicken and cook till the chicken is cooked through. Once done, drain the water and keep aside.In a\n",
      "\n",
      "Temperature 1.0: To prepare chicken curry, firstly heat oil in a heavy bottomed pan. Add onions and saute till they turn translucent.Add cumin seeds, turmeric powder, red chilli powder and salt to taste. Saute for a couple of minutes till the onions become soft and mushy.\n",
      "\n",
      "Temperature 1.5: To prepare chicken curry, we will first make the masala.Heat oil in a heavy bottomed pan. Add mustard seeds, green chillies, coriander leaves and let it splutter.Add chopped onions and saute till they turn golden brown in colour.Saut and cook till the\n"
     ]
    }
   ],
   "source": [
    "# Enhanced text generation function with better control\n",
    "def generate_text_enhanced(prompt, max_length=100, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Generate text with enhanced parameters for better control.\n",
    "    \"\"\"\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate with more sophisticated parameters\n",
    "    output = model_finetuned.generate(\n",
    "        input_ids, \n",
    "        max_length=max_length, \n",
    "        temperature=temperature,\n",
    "        num_beams=5,                    # Beam search for quality\n",
    "        no_repeat_ngram_size=2,         # Prevent repetition\n",
    "        do_sample=True,                 # Enable sampling\n",
    "        top_k=50,                       # Top-k sampling\n",
    "        top_p=0.95,                     # Nucleus sampling\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "# Test different temperatures\n",
    "test_prompt = \"To prepare chicken curry,\"\n",
    "temperatures = [0.5, 1.0, 1.5]\n",
    "\n",
    "print(\"üå°Ô∏è Temperature Comparison:\")\n",
    "for temp in temperatures:\n",
    "    output = generate_text_enhanced(test_prompt, max_length=60, temperature=temp)\n",
    "    print(f\"\\nTemperature {temp}: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Simple Gradio Interface**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "0kdKV1HzwEv7"
   },
   "outputs": [],
   "source": [
    "# Create a simple Gradio interface for text generation\n",
    "iface = gr.Interface(\n",
    "    fn=generate_text_enhanced,        # Function to call for text generation\n",
    "    inputs=[\n",
    "        \n",
    "        gr.Textbox(label=\"Recipe Prompt\", placeholder=\"Enter recipe start (e.g., 'To make dal,')\"),\n",
    "        gr.Slider(minimum=50, maximum=200, value=100, label=\"Max Length\"),\n",
    "        gr.Slider(minimum=0.1, maximum=2.0, value=1.0, label=\"Temperature\")\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Generated Recipe Step\"),\n",
    "    title=\"üçõ Indian Recipe Generator\",\n",
    "    description=\"Generate Indian recipe instructions using fine-tuned GPT-2\",\n",
    "    examples=[\n",
    "        [\"To make dal,\", 100, 1.0],\n",
    "        [\"To prepare chicken curry,\", 120, 0.8],\n",
    "        [\"First, heat oil in a pan\", 80, 1.2]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "PdM7fChwwF2Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://26646c62fbefcc0503.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://26646c62fbefcc0503.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Launch the Gradio interface\n",
    "iface.launch(share=True)  # share=True creates a public link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxSUhP740ign"
   },
   "source": [
    "### **Advanced: Model Comparison Interface**\n",
    "\n",
    "**üî¨ Advanced Section** - Compare original GPT-2 vs fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "gehLx_5s0TOz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 148/148 [00:00<00:00, 172.22it/s, Materializing param=transformer.wte.weight]\n",
      "\u001b[1mGPT2LMHeadModel LOAD REPORT\u001b[0m from: gpt2\n",
      "Key                  | Status     |  | \n",
      "---------------------+------------+--+-\n",
      "h.{0...11}.attn.bias | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original GPT-2 model loaded for comparison\n"
     ]
    }
   ],
   "source": [
    "# Load original GPT-2 model for comparison\n",
    "model_original = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "print(\"Original GPT-2 model loaded for comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "BYtGpBua36VO"
   },
   "outputs": [],
   "source": [
    "# Generalized generation function that works with any model\n",
    "def generate_text_using(model, prompt, temperature=1.0, max_length=120):\n",
    "    \"\"\"\n",
    "    Generate text using a specific model.\n",
    "    \n",
    "    Args:\n",
    "        model: The language model to use\n",
    "        prompt: Input text prompt\n",
    "        temperature: Generation temperature\n",
    "        max_length: Maximum generation length\n",
    "    \n",
    "    Returns:\n",
    "        Generated text string\n",
    "    \"\"\"\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    output = model.generate(\n",
    "        input_ids, \n",
    "        max_length=max_length, \n",
    "        num_beams=5, \n",
    "        no_repeat_ngram_size=2, \n",
    "        top_k=50, \n",
    "        top_p=0.95, \n",
    "        temperature=temperature,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "oBAQTgSa4CIQ"
   },
   "outputs": [],
   "source": [
    "# Function to compare both models side by side\n",
    "def generate_texts_compare(prompt, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Generate text using both original and fine-tuned models for comparison.\n",
    "    \n",
    "    Returns:\n",
    "        List containing [original_output, finetuned_output]\n",
    "    \"\"\"\n",
    "    original_output = generate_text_using(model_original, prompt, temperature=temperature)\n",
    "    finetuned_output = generate_text_using(model_finetuned, prompt, temperature=temperature)\n",
    "    \n",
    "    return [original_output, finetuned_output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "YVf0JosT4OmK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Model Comparison Test:\n",
      "Prompt: To make Masala Karela\n",
      "\n",
      "üìÑ Original GPT-2: To make Masala Karela's case even more compelling, it's important to understand that he's not the only one who's been targeted in the past.\n",
      "\n",
      "In fact, many of the people who have been singled out for this kind of harassment are also the ones who've been victims of sexual harassment or assault. This is not to say that all of these people aren't victims, but rather that they should be treated with the same respect and dignity as the rest of us. It's also important for us to recognize that these kinds of attacks are not isolated incidents, and that we need\n",
      "\n",
      "üçõ Fine-tuned GPT-2: To make Masala Karela Recipe, first heat oil in a heavy bottomed pan. Add cumin seeds and let it crackle.Add garlic and saute till the garlic turns translucent. Now add turmeric powder, red chilli powder and salt. Saute for a few seconds.Now add chopped onions and cook till they turn translucent and turn golden brown in colour. Turn off the flame and allow it to cool down.Once the onions are translucent, drain the water from the pan and keep aside.In a large mixing bowl, combine all the ingredients mentioned above. Mix well and add\n"
     ]
    }
   ],
   "source": [
    "# Test the comparison function\n",
    "test_prompt = \"To make Masala Karela\"\n",
    "original_output, finetuned_output = generate_texts_compare(test_prompt)\n",
    "\n",
    "print(\"üîÑ Model Comparison Test:\")\n",
    "print(f\"Prompt: {test_prompt}\")\n",
    "print(f\"\\nüìÑ Original GPT-2: {original_output}\")\n",
    "print(f\"\\nüçõ Fine-tuned GPT-2: {finetuned_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Model Differences\n",
    "<details>\n",
    "<summary>What to look for in model comparisons</summary>\n",
    "\n",
    "Compare the outputs for:\n",
    "- **Domain relevance**: Does the fine-tuned model stay on topic?\n",
    "- **Cooking terminology**: Does it use appropriate cooking terms?\n",
    "- **Step structure**: Are the instructions well-structured?\n",
    "- **Cultural context**: Does it understand Indian cooking methods?\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "M_wlJvlO0m8t"
   },
   "outputs": [],
   "source": [
    "# Advanced Gradio interface for model comparison\n",
    "comparison_interface = gr.Interface(\n",
    "    fn=generate_texts_compare,\n",
    "    inputs=[\n",
    "        gr.Textbox(\n",
    "            label=\"Recipe Prompt\", \n",
    "            placeholder=\"Enter recipe start (e.g., 'To make dal,')\",\n",
    "            lines=2\n",
    "        ),\n",
    "        gr.Slider(\n",
    "            minimum=0.1, \n",
    "            maximum=2.0, \n",
    "            value=1.0, \n",
    "            label=\"Temperature\",\n",
    "            info=\"Controls randomness: lower = more focused, higher = more creative\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"üìÑ Original GPT-2 Output\", lines=4),\n",
    "        gr.Textbox(label=\"üçõ Fine-tuned GPT-2 Output\", lines=4)\n",
    "    ],\n",
    "    title=\"üî¨ Model Comparison: Original vs Fine-tuned GPT-2\",\n",
    "    description=\"Compare how the original GPT-2 and fine-tuned model respond to recipe prompts\",\n",
    "    examples=[\n",
    "        [\"To make dal,\", 0.8],\n",
    "        [\"To prepare chicken curry,\", 1.0],\n",
    "        [\"First, heat oil in a pan\", 1.2]\n",
    "    ],\n",
    "    article=\"\"\"\n",
    "    ### üìä How to Interpret Results:\n",
    "    - **Domain Relevance**: Fine-tuned model should stay focused on cooking\n",
    "    - **Terminology**: Look for cooking-specific vocabulary\n",
    "    - **Structure**: Well-formed recipe instructions\n",
    "    - **Cultural Context**: Indian cooking methods and ingredients\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "UlAeprAc0h_Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://738dc4cbe742a3b334.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://738dc4cbe742a3b334.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Launch the comparison interface\n",
    "comparison_interface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
